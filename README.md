
---

# ğŸ“Œ Problem Statement

With the rapid growth of generative AI, users increasingly rely on AI-generated content for academics, research, and professional tasks. However, AI systems often produce **hallucinated facts, misleading claims, and fake or broken citations**, making it difficult for users to judge the credibility of the information.
There is a need for a unified platform that helps users **verify AI-generated text before trusting or using it**.

---

# ğŸ” Project Name

**AI Verifier â€“ Trust AI Before You Use It**

---

# ğŸ‘¥ Team Name

**Code Cadets**

---

# ğŸŒ Deployed Link (Optional)

Frontend: [https://codecadet-psi.vercel.app/](https://codecadet-psi.vercel.app/)
Backend API: [https://ps03-ai-verifier.onrender.com](https://ps03-ai-verifier.onrender.com)
---

# ğŸ¥ 2-Minute Demonstration Video Link

Demo Video:
[https://drive.google.com/drive/folders/19ylCFDsXkA5bGek7ANolIf9Px_YyBWwJ?usp=sharing](https://drive.google.com/drive/folders/19ylCFDsXkA5bGek7ANolIf9Px_YyBWwJ?usp=sharing)
*(Permission: Anyone with the link can view)*

---

# ğŸ“Š PPT Link

Project PPT (PDF):
[https://www.canva.com/design/DAG9YUo6zOw/hPAt-6vwC4CjDQnhgY3fDA/edit?utm_content=DAG9YUo6zOw&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton](https://www.canva.com/design/DAG9YUo6zOw/hPAt-6vwC4CjDQnhgY3fDA/edit?utm_content=DAG9YUo6zOw&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)
*(Permission: Anyone with the link can view)*

---

# ğŸš€ Project Overview

**AI Verifier** is a web-based AI-powered platform designed to verify the credibility of AI-generated content.
It analyzes text to detect hallucinations, validate factual claims, identify fake or broken citations, and generate an overall **Trust Score**.

The platform acts as a **trust layer between users and AI**, helping users make informed decisions before using AI-generated information.

---

# âœ¨ Key Features

### âœ… Claim Verification

* Breaks text into individual claims
* Classifies claims as **Valid / Questionable / False**

### âŒ Hallucination Detection

* Detects misleading or factually incorrect AI statements

### ğŸ“š Citation Analysis

* Identifies **fake citations**
* Detects **broken or invalid references**

### ğŸ“Š Trust Score

* Generates an overall reliability score from **0â€“100**

### ğŸ¨ Premium UI / UX

* Glassmorphism design
* Responsive across all devices

---

# ğŸ› ï¸ Tech Stack

### Frontend

* React + TypeScript
* Tailwind CSS
* shadcn/ui
* Lucide Icons

### Backend

* FastAPI
* Python
* AI/ML-based verification logic

### Deployment

* Frontend: Vercel
* Backend: Render

---

# âš™ï¸ Setup & Installation Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/ByteQuest-2025/GFGBQ-Team-code-cadets
cd GFGBQ-Team-code-cadets
```

### 2ï¸âƒ£ Install Dependencies

```bash
npm install
```

### 3ï¸âƒ£ Run the Development Server

```bash
npm run dev
```

### 4ï¸âƒ£ Open in Browser

```
http://localhost:5173
```

---

# ğŸ“Œ Usage Instructions

1. Paste AI-generated text into the input field
2. Click **Verify**
3. View:

   * Claim verification results
   * Fake / broken citations
   * Overall Trust Score

---

# ğŸ–¼ï¸ Screenshots

Include screenshots of:

* Home page
* Verification results
* Trust score display

*(Screenshots attached in the repository)*

---

# ğŸ§  Use Cases

* Students & Researchers
* Journalists & Writers
* Developers using AI tools
* Educators
* Enterprises validating AI outputs

---

# ğŸ† Hackathon Readiness

âœ” Working end-to-end solution
âœ” Clear problemâ€“solution mapping
âœ” Strong AI trust narrative
âœ” Clean UI & demo-friendly

---

# ğŸ”® Future Enhancements

* Inline claim highlighting
* Export verification reports (PDF)
* Browser extension
* User authentication & history
* Dark / Light mode toggle

---

# ğŸ“„ License

This project is licensed under the **MIT License**.

---

### ğŸ” *AI Verifier â€“ Because trusting AI should be a choice, not a risk.*

---

